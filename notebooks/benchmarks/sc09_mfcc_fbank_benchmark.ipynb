{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC09 speech keyword detection benchmark model using MFCC/FBANK features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will train different classifiers on ER on the SC09 (Speech commands from 0 to 9) dataset using MFCC/FBANK features.\n",
    "\n",
    "Moreover, we provide the performance that can acquired by classifying samples by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, balanced_accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_train_dir = os.path.join(\"/media\", \"datastore\", \"c-matsty-data\", \"SpeechCommands_Preproc_2_training_MFCC\")\n",
    "mfcc_train_input_path = os.path.join(mfcc_train_dir, \"input_data\")\n",
    "mfcc_train_labels_path = os.path.join(mfcc_train_dir, \"labels\")\n",
    "mfcc_train_actors_path = os.path.join(mfcc_train_dir, \"actors\")\n",
    "fbank_train_dir = os.path.join(\"/media\", \"datastore\", \"c-matsty-data\", \"SpeechCommands_Preproc_2_training_FBANK\")\n",
    "fbank_train_input_path = os.path.join(fbank_train_dir, \"input_data\")\n",
    "fbank_train_labels_path = os.path.join(fbank_train_dir, \"labels\")\n",
    "fbank_train_actors_path = os.path.join(fbank_train_dir, \"actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_test_dir = os.path.join(\"/media\", \"datastore\", \"c-matsty-data\", \"SpeechCommands_Preproc_2_test_MFCC\")\n",
    "mfcc_test_input_path = os.path.join(mfcc_test_dir, \"input_data\")\n",
    "mfcc_test_labels_path = os.path.join(mfcc_test_dir, \"labels\")\n",
    "mfcc_test_actors_path = os.path.join(mfcc_test_dir, \"actors\")\n",
    "fbank_test_dir = os.path.join(\"/media\", \"datastore\", \"c-matsty-data\", \"SpeechCommands_Preproc_2_test_FBANK\")\n",
    "fbank_test_input_path = os.path.join(fbank_test_dir, \"input_data\")\n",
    "fbank_test_labels_path = os.path.join(fbank_test_dir, \"labels\")\n",
    "fbank_test_actors_path = os.path.join(fbank_test_dir, \"actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_path, labels_path, actors_path):\n",
    "    X = []\n",
    "    Y = []\n",
    "    A = []\n",
    "    for input_file_name in os.listdir(input_path):\n",
    "        file_name = input_file_name.split(\".\")[0]\n",
    "        x = np.load(os.path.join(input_path, input_file_name))\n",
    "        y = np.load(os.path.join(labels_path, file_name + \"_labels.npy\"))[..., np.newaxis]\n",
    "        actors = np.load(os.path.join(actors_path, file_name + \"_actors.npy\"))[..., np.newaxis]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        A.append(actors)\n",
    "    X = np.vstack(X)\n",
    "    Y = np.vstack(Y)\n",
    "    A = np.vstack(A)\n",
    "    return X, Y, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc_tr, y_mfcc_tr, actors_mfcc_tr = load_data(mfcc_train_input_path, mfcc_train_labels_path, mfcc_train_actors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fbank_tr, y_fbank_tr, actors_fbank_tr = load_data(fbank_train_input_path, fbank_train_labels_path, fbank_train_actors_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc_ts, y_mfcc_ts, actors_mfcc_ts = load_data(mfcc_test_input_path, mfcc_test_labels_path, mfcc_test_actors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fbank_ts, y_fbank_ts, actors_fbank_ts = load_data(fbank_test_input_path, fbank_test_labels_path, fbank_test_actors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {value: index  for index, value in enumerate(np.unique(y_mfcc_tr))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn labels from strings to integer identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mfcc_tr = np.vectorize(label_dict.get)(y_mfcc_tr)\n",
    "y_fbank_tr = np.vectorize(label_dict.get)(y_fbank_tr)\n",
    "y_mfcc_ts = np.vectorize(label_dict.get)(y_mfcc_ts)\n",
    "y_fbank_ts = np.vectorize(label_dict.get)(y_fbank_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape input arrays and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc_tr = X_mfcc_tr.reshape((X_mfcc_tr.shape[0], X_mfcc_tr.shape[1] * X_mfcc_tr.shape[2]))\n",
    "X_mfcc_ts = X_mfcc_ts.reshape((X_mfcc_ts.shape[0], X_mfcc_ts.shape[1] * X_mfcc_ts.shape[2]))\n",
    "X_fbank_tr = X_fbank_tr.reshape((X_fbank_tr.shape[0], X_fbank_tr.shape[1] * X_fbank_tr.shape[2]))\n",
    "X_fbank_ts = X_fbank_ts.reshape((X_fbank_ts.shape[0], X_fbank_ts.shape[1] * X_fbank_ts.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mfcc_tr = y_mfcc_tr.flatten()\n",
    "y_mfcc_ts = y_mfcc_ts.flatten()\n",
    "y_fbank_tr = y_fbank_tr.flatten()\n",
    "y_fbank_ts = y_fbank_ts.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_mean = X_mfcc_tr.mean()\n",
    "mfcc_std = X_mfcc_tr.std()\n",
    "X_mfcc_tr = (X_mfcc_tr - mfcc_mean) / mfcc_std \n",
    "X_mfcc_ts = (X_mfcc_ts - mfcc_mean) / mfcc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbank_mean = X_fbank_tr.mean()\n",
    "fbank_std = X_fbank_tr.std()\n",
    "X_fbank_tr = (X_fbank_tr - fbank_mean) / fbank_std \n",
    "X_fbank_ts = (X_fbank_ts - fbank_mean) / fbank_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = [len(y_mfcc_tr[y_mfcc_tr == i]) for i in label_dict.values()]\n",
    "class_weights = [max(class_counts)/class_count for class_count in class_counts]\n",
    "class_weight_dict = {class_idx: class_weight for class_idx, class_weight in zip(label_dict.values(), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eight': 0,\n",
       " 'five': 1,\n",
       " 'four': 2,\n",
       " 'nine': 3,\n",
       " 'one': 4,\n",
       " 'seven': 5,\n",
       " 'six': 6,\n",
       " 'three': 7,\n",
       " 'two': 8,\n",
       " 'zero': 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test logistic regression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_class = 'multinomial'\n",
    "model = LogisticRegression(multi_class=multi_class, max_iter=15000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = [class_weight_dict[label] for label in y_mfcc_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X_mfcc_tr, y_mfcc_tr, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.48      0.46       257\n",
      "           1       0.46      0.43      0.45       270\n",
      "           2       0.58      0.53      0.56       253\n",
      "           3       0.41      0.42      0.42       259\n",
      "           4       0.37      0.34      0.36       248\n",
      "           5       0.42      0.48      0.45       239\n",
      "           6       0.66      0.57      0.61       244\n",
      "           7       0.42      0.40      0.41       267\n",
      "           8       0.34      0.33      0.33       264\n",
      "           9       0.49      0.58      0.53       250\n",
      "\n",
      "    accuracy                           0.45      2551\n",
      "   macro avg       0.46      0.46      0.46      2551\n",
      "weighted avg       0.46      0.45      0.45      2551\n",
      "\n",
      "0.4561950963835672\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_mfcc_ts)\n",
    "print(classification_report(y_mfcc_ts, y_preds))\n",
    "print(balanced_accuracy_score(y_mfcc_ts, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with FBANK features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class=multi_class, max_iter=15000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X_fbank_tr, y_fbank_tr, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.55      0.53       257\n",
      "           1       0.56      0.45      0.50       270\n",
      "           2       0.64      0.64      0.64       253\n",
      "           3       0.51      0.47      0.49       259\n",
      "           4       0.42      0.45      0.43       248\n",
      "           5       0.54      0.43      0.48       239\n",
      "           6       0.65      0.54      0.59       244\n",
      "           7       0.34      0.61      0.43       267\n",
      "           8       0.45      0.42      0.43       264\n",
      "           9       0.44      0.32      0.37       250\n",
      "\n",
      "    accuracy                           0.49      2551\n",
      "   macro avg       0.51      0.49      0.49      2551\n",
      "weighted avg       0.50      0.49      0.49      2551\n",
      "\n",
      "0.48784181923162356\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_fbank_ts)\n",
    "print(classification_report(y_fbank_ts, y_preds))\n",
    "print(balanced_accuracy_score(y_fbank_ts, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test RandomForest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=400, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X_mfcc_tr, y_mfcc_tr, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.73       257\n",
      "           1       0.70      0.70      0.70       270\n",
      "           2       0.81      0.82      0.81       253\n",
      "           3       0.76      0.74      0.75       259\n",
      "           4       0.79      0.67      0.72       248\n",
      "           5       0.86      0.84      0.85       239\n",
      "           6       0.84      0.86      0.85       244\n",
      "           7       0.82      0.80      0.81       267\n",
      "           8       0.74      0.69      0.71       264\n",
      "           9       0.81      0.85      0.83       250\n",
      "\n",
      "    accuracy                           0.78      2551\n",
      "   macro avg       0.78      0.78      0.78      2551\n",
      "weighted avg       0.78      0.78      0.78      2551\n",
      "\n",
      "0.7774368401592572\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_mfcc_ts)\n",
    "print(classification_report(y_mfcc_ts, y_preds))\n",
    "print(balanced_accuracy_score(y_mfcc_ts, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with FBANK features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=400, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X_fbank_tr, y_fbank_tr, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       257\n",
      "           1       0.80      0.83      0.81       270\n",
      "           2       0.82      0.81      0.82       253\n",
      "           3       0.85      0.83      0.84       259\n",
      "           4       0.83      0.79      0.81       248\n",
      "           5       0.89      0.85      0.87       239\n",
      "           6       0.89      0.89      0.89       244\n",
      "           7       0.82      0.85      0.84       267\n",
      "           8       0.81      0.81      0.81       264\n",
      "           9       0.85      0.85      0.85       250\n",
      "\n",
      "    accuracy                           0.84      2551\n",
      "   macro avg       0.84      0.84      0.84      2551\n",
      "weighted avg       0.84      0.84      0.84      2551\n",
      "\n",
      "0.8384048972425495\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_fbank_ts)\n",
    "print(classification_report(y_fbank_ts, y_preds))\n",
    "print(balanced_accuracy_score(y_fbank_ts, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chance level performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f1: 0.09975909006229454\n",
      "Macro recall: 0.09986420130659657\n",
      "Macro precision: 0.09991772619634794\n"
     ]
    }
   ],
   "source": [
    "trials = 100\n",
    "avg_f1 = 0.0\n",
    "avg_prec = 0.0\n",
    "avg_rec = 0.0\n",
    "for i in range(trials):\n",
    "    y_preds = np.random.choice(np.unique(y_fbank_tr), y_fbank_ts.shape[0])\n",
    "    avg_f1 += f1_score(y_fbank_ts, y_preds, average='macro')\n",
    "    avg_prec += precision_score(y_fbank_ts, y_preds, average='macro')\n",
    "    avg_rec += recall_score(y_fbank_ts, y_preds, average='macro')\n",
    "avg_f1 /= trials\n",
    "avg_prec /= trials\n",
    "avg_rec /= trials\n",
    "print(\"Macro f1: {}\".format(avg_f1))\n",
    "print(\"Macro recall: {}\".format(avg_rec))\n",
    "print(\"Macro precision: {}\".format(avg_prec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
